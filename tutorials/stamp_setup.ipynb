{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7454c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stamp.modeling import stamp\n",
    "from stamp.local import get_local_config\n",
    "import torch\n",
    "\n",
    "local_config = get_local_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ca67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_temporal_channels = 5\n",
    "n_spatial_channels = 20\n",
    "\n",
    "# Setup default model configuration\n",
    "dropout_rate = 0.3\n",
    "config = {\n",
    "    'input_dim': 1024,\n",
    "    'D': 128,\n",
    "    'n_temporal_channels': n_temporal_channels,\n",
    "    'n_spatial_channels': n_spatial_channels,\n",
    "    'encoder_aggregation': 'attention_pooling',\n",
    "    'n_classes': 1,\n",
    "    'initial_proj_params': \n",
    "        {\n",
    "            'type': 'full',\n",
    "            'dropout_rate': dropout_rate\n",
    "        },\n",
    "    'final_classifier_params': None,\n",
    "    'use_batch_norm': False,\n",
    "    'use_instance_norm': True,\n",
    "    'pe_params': \n",
    "        {\n",
    "            'pe_type': 'basic',\n",
    "            'use_token_positional_embeddings': True,\n",
    "            'use_spatial_positional_embeddings': True,\n",
    "            'use_temporal_positional_embeddings': True\n",
    "        },\n",
    "    'transformer_params': None,\n",
    "    'gated_mlp_params':\n",
    "        {\n",
    "            'type': 'criss_cross',\n",
    "            'n_layers': 8,\n",
    "            'dim_feedforward': 256,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'combination_mode': 'concat',\n",
    "            'recurrent': False\n",
    "        },\n",
    "    'mhap_params': \n",
    "        {\n",
    "            'A': 4,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'n_queries_per_head': 8,\n",
    "            'query_combination': 'weighted_sum',\n",
    "            'lambda_for_residual': 0.1,\n",
    "        }\n",
    "}\n",
    "\n",
    "model = stamp.STAMP(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89228f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters per layer:\n",
      "  : 720401 parameters\n",
      "  data_norm: 2048 parameters\n",
      "  linear: 131200 parameters\n",
      "  linear.1: 131200 parameters\n",
      "  pos_embed: 12800 parameters\n",
      "  spatial_embed: 2560 parameters\n",
      "  temporal_embed: 640 parameters\n",
      "  gated_mlp: 537104 parameters\n",
      "  gated_mlp.0: 67138 parameters\n",
      "  gated_mlp.0.norm: 256 parameters\n",
      "  gated_mlp.0.proj_1: 33024 parameters\n",
      "  gated_mlp.0.sgu_temporal: 286 parameters\n",
      "  gated_mlp.0.sgu_temporal.norm: 256 parameters\n",
      "  gated_mlp.0.sgu_temporal.spatial_proj: 30 parameters\n",
      "  gated_mlp.0.sgu_spatial: 676 parameters\n",
      "  gated_mlp.0.sgu_spatial.norm: 256 parameters\n",
      "  gated_mlp.0.sgu_spatial.spatial_proj: 420 parameters\n",
      "  gated_mlp.0.proj_2: 32896 parameters\n",
      "  gated_mlp.1: 67138 parameters\n",
      "  gated_mlp.1.norm: 256 parameters\n",
      "  gated_mlp.1.proj_1: 33024 parameters\n",
      "  gated_mlp.1.sgu_temporal: 286 parameters\n",
      "  gated_mlp.1.sgu_temporal.norm: 256 parameters\n",
      "  gated_mlp.1.sgu_temporal.spatial_proj: 30 parameters\n",
      "  gated_mlp.1.sgu_spatial: 676 parameters\n",
      "  gated_mlp.1.sgu_spatial.norm: 256 parameters\n",
      "  gated_mlp.1.sgu_spatial.spatial_proj: 420 parameters\n",
      "  gated_mlp.1.proj_2: 32896 parameters\n",
      "  gated_mlp.2: 67138 parameters\n",
      "  gated_mlp.2.norm: 256 parameters\n",
      "  gated_mlp.2.proj_1: 33024 parameters\n",
      "  gated_mlp.2.sgu_temporal: 286 parameters\n",
      "  gated_mlp.2.sgu_temporal.norm: 256 parameters\n",
      "  gated_mlp.2.sgu_temporal.spatial_proj: 30 parameters\n",
      "  gated_mlp.2.sgu_spatial: 676 parameters\n",
      "  gated_mlp.2.sgu_spatial.norm: 256 parameters\n",
      "  gated_mlp.2.sgu_spatial.spatial_proj: 420 parameters\n",
      "  gated_mlp.2.proj_2: 32896 parameters\n",
      "  gated_mlp.3: 67138 parameters\n",
      "  gated_mlp.3.norm: 256 parameters\n",
      "  gated_mlp.3.proj_1: 33024 parameters\n",
      "  gated_mlp.3.sgu_temporal: 286 parameters\n",
      "  gated_mlp.3.sgu_temporal.norm: 256 parameters\n",
      "  gated_mlp.3.sgu_temporal.spatial_proj: 30 parameters\n",
      "  gated_mlp.3.sgu_spatial: 676 parameters\n",
      "  gated_mlp.3.sgu_spatial.norm: 256 parameters\n",
      "  gated_mlp.3.sgu_spatial.spatial_proj: 420 parameters\n",
      "  gated_mlp.3.proj_2: 32896 parameters\n",
      "  gated_mlp.4: 67138 parameters\n",
      "  gated_mlp.4.norm: 256 parameters\n",
      "  gated_mlp.4.proj_1: 33024 parameters\n",
      "  gated_mlp.4.sgu_temporal: 286 parameters\n",
      "  gated_mlp.4.sgu_temporal.norm: 256 parameters\n",
      "  gated_mlp.4.sgu_temporal.spatial_proj: 30 parameters\n",
      "  gated_mlp.4.sgu_spatial: 676 parameters\n",
      "  gated_mlp.4.sgu_spatial.norm: 256 parameters\n",
      "  gated_mlp.4.sgu_spatial.spatial_proj: 420 parameters\n",
      "  gated_mlp.4.proj_2: 32896 parameters\n",
      "  gated_mlp.5: 67138 parameters\n",
      "  gated_mlp.5.norm: 256 parameters\n",
      "  gated_mlp.5.proj_1: 33024 parameters\n",
      "  gated_mlp.5.sgu_temporal: 286 parameters\n",
      "  gated_mlp.5.sgu_temporal.norm: 256 parameters\n",
      "  gated_mlp.5.sgu_temporal.spatial_proj: 30 parameters\n",
      "  gated_mlp.5.sgu_spatial: 676 parameters\n",
      "  gated_mlp.5.sgu_spatial.norm: 256 parameters\n",
      "  gated_mlp.5.sgu_spatial.spatial_proj: 420 parameters\n",
      "  gated_mlp.5.proj_2: 32896 parameters\n",
      "  gated_mlp.6: 67138 parameters\n",
      "  gated_mlp.6.norm: 256 parameters\n",
      "  gated_mlp.6.proj_1: 33024 parameters\n",
      "  gated_mlp.6.sgu_temporal: 286 parameters\n",
      "  gated_mlp.6.sgu_temporal.norm: 256 parameters\n",
      "  gated_mlp.6.sgu_temporal.spatial_proj: 30 parameters\n",
      "  gated_mlp.6.sgu_spatial: 676 parameters\n",
      "  gated_mlp.6.sgu_spatial.norm: 256 parameters\n",
      "  gated_mlp.6.sgu_spatial.spatial_proj: 420 parameters\n",
      "  gated_mlp.6.proj_2: 32896 parameters\n",
      "  gated_mlp.7: 67138 parameters\n",
      "  gated_mlp.7.norm: 256 parameters\n",
      "  gated_mlp.7.proj_1: 33024 parameters\n",
      "  gated_mlp.7.sgu_temporal: 286 parameters\n",
      "  gated_mlp.7.sgu_temporal.norm: 256 parameters\n",
      "  gated_mlp.7.sgu_temporal.spatial_proj: 30 parameters\n",
      "  gated_mlp.7.sgu_spatial: 676 parameters\n",
      "  gated_mlp.7.sgu_spatial.norm: 256 parameters\n",
      "  gated_mlp.7.sgu_spatial.spatial_proj: 420 parameters\n",
      "  gated_mlp.7.proj_2: 32896 parameters\n",
      "  multi_head_attention_pooling: 33920 parameters\n",
      "  multi_head_attention_pooling.W: 16384 parameters\n",
      "  multi_head_attention_pooling.W.0: 4096 parameters\n",
      "  multi_head_attention_pooling.W.1: 4096 parameters\n",
      "  multi_head_attention_pooling.W.2: 4096 parameters\n",
      "  multi_head_attention_pooling.W.3: 4096 parameters\n",
      "  multi_head_attention_pooling.out_proj: 16512 parameters\n",
      "  classifier: 129 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters per layer:\")\n",
    "for name, module in model.named_modules():\n",
    "    if list(module.parameters()):  # Check if the module has any parameters\n",
    "        param_count = sum(p.numel() for p in module.parameters())\n",
    "        print(f\"  {name}: {param_count} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddcfbe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(64, n_temporal_channels, n_spatial_channels, 1024)  # (batch_size, n_temporal_tokens, n_spatial_tokens, input_dim)\n",
    "y, _ = model(x, return_attention=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a03918b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOMENTEEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
